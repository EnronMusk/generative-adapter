{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions to load the model, create an adaptor for LoRA weights,\n",
    "# and perform conditional text generation.\n",
    "\n",
    "from fastlora.config import FastLoraConfig\n",
    "from fastlora.model import FastLoraModelForCausalLM, FastLoraModel, get_peft_model_state_dict, set_peft_model_state_dict, load_pretrained_model\n",
    "import peft.peft_model as peft_model\n",
    "import peft.mapping as peft_mapping\n",
    "\n",
    "## monkey patching\n",
    "peft_model.PEFT_TYPE_TO_MODEL_MAPPING.update({\"FASTLORA\": FastLoraModel})\n",
    "peft_mapping.PEFT_TYPE_TO_CONFIG_MAPPING.update({\"FASTLORA\": FastLoraConfig})\n",
    "peft_model.get_peft_model_state_dict = get_peft_model_state_dict\n",
    "peft_model.set_peft_model_state_dict = set_peft_model_state_dict\n",
    "\n",
    "from fastlora.eval_utils import load_model_and_tokenizer\n",
    "from fastlora.eval_utils import fastlora_generate_adaptor\n",
    "from fastlora.eval_utils import fastlora_conditional_generate\n",
    "from pathlib import Path\n",
    "import json\n",
    "import torch\n",
    "from peft.config import PeftConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the pretrained model checkpoint and the device to run on.\n",
    "model_name_or_path = \"generative-adaptor/Generative-Adapter-Mistral-7B-Instruct-v0.2\"\n",
    "device = 'cuda'\n",
    "torch_dtype = torch.bfloat16\n",
    "attn_implementation = 'sdpa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:03<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peft_config FastLoraConfig(peft_type='FASTLORA', auto_mapping=None, base_model_name_or_path='mistralai/Mistral-7B-Instruct-v0.2', revision=None, task_type='FAST_LORA_CAUSAL_LM', inference_mode=True, fastlora_r=1024, fastlora_inter_size=1024, fastlora_window=1024, fastlora_max_rank=128, fastlora_attn_len=8192, fastlora_gist_len=0, fastlora_alpha=64.0, fastlora_dropout=0.0, fastlora_arch='aassbb', fastlora_norm='svd', fastlora_init='default', fastlora_merge='pre-norm-sum', fastlora_param=['o_proj'], fastlora_training_attention_mask='default', target_modules=['o_proj'], lora_r=0, lora_alpha=0, lora_dropout=0.0, lora_param=None, layer_replication=None, megatron_config=None, bias='none')\n",
      "[WARNING] we apply a monkey patch to the function `get_peft_model_state_dict` to support FastLora model\n",
      "missing_keys: []\n",
      "peft_model_state_dict.keys(): dict_keys(['base_model.model.model.layers.0.base_layer.self_attn.o_proj.fastlora_A1.weight', 'base_model.model.model.layers.0.base_layer.self_attn.o_proj.fastlora_A2.weight', 'base_model.model.model.layers.0.base_layer.self_attn.o_proj.fastlora_A3.weight', 'base_model.model.model.layers.0.base_layer.self_attn.o_proj.fastlora_B.weight', 'base_model.model.model.layers.0.base_layer.self_attn.o_proj.fastlora_hidden_state_norm.weight', 'base_model.model.model.layers.1.base_layer.self_attn.o_proj.fastlora_A1.weight', 'base_model.model.model.layers.1.base_layer.self_attn.o_proj.fastlora_A2.weight', 'base_model.model.model.layers.1.base_layer.self_attn.o_proj.fastlora_A3.weight', 'base_model.model.model.layers.1.base_layer.self_attn.o_proj.fastlora_B.weight', 'base_model.model.model.layers.1.base_layer.self_attn.o_proj.fastlora_hidden_state_norm.weight', 'base_model.model.model.layers.10.base_layer.self_attn.o_proj.fastlora_A1.weight', 'base_model.model.model.layers.10.base_layer.self_attn.o_proj.fastlora_A2.weight', 'base_model.model.model.layers.10.base_layer.self_attn.o_proj.fastlora_A3.weight', 'base_model.model.model.layers.10.base_layer.self_attn.o_proj.fastlora_B.weight', 'base_model.model.model.layers.10.base_layer.self_attn.o_proj.fastlora_hidden_state_norm.weight', 'base_model.model.model.layers.11.base_layer.self_attn.o_proj.fastlora_A1.weight', 'base_model.model.model.layers.11.base_layer.self_attn.o_proj.fastlora_A2.weight', 'base_model.model.model.layers.11.base_layer.self_attn.o_proj.fastlora_A3.weight', 'base_model.model.model.layers.11.base_layer.self_attn.o_proj.fastlora_B.weight', 'base_model.model.model.layers.11.base_layer.self_attn.o_proj.fastlora_hidden_state_norm.weight', 'base_model.model.model.layers.12.base_layer.self_attn.o_proj.fastlora_A1.weight', 'base_model.model.model.layers.12.base_layer.self_attn.o_proj.fastlora_A2.weight', 'base_model.model.model.layers.12.base_layer.self_attn.o_proj.fastlora_A3.weight', 'base_model.model.model.layers.12.base_layer.self_attn.o_proj.fastlora_B.weight', 'base_model.model.model.layers.12.base_layer.self_attn.o_proj.fastlora_hidden_state_norm.weight', 'base_model.model.model.layers.13.base_layer.self_attn.o_proj.fastlora_A1.weight', 'base_model.model.model.layers.13.base_layer.self_attn.o_proj.fastlora_A2.weight', 'base_model.model.model.layers.13.base_layer.self_attn.o_proj.fastlora_A3.weight', 'base_model.model.model.layers.13.base_layer.self_attn.o_proj.fastlora_B.weight', 'base_model.model.model.layers.13.base_layer.self_attn.o_proj.fastlora_hidden_state_norm.weight', 'base_model.model.model.layers.14.base_layer.self_attn.o_proj.fastlora_A1.weight', 'base_model.model.model.layers.14.base_layer.self_attn.o_proj.fastlora_A2.weight', 'base_model.model.model.layers.14.base_layer.self_attn.o_proj.fastlora_A3.weight', 'base_model.model.model.layers.14.base_layer.self_attn.o_proj.fastlora_B.weight', 'base_model.model.model.layers.14.base_layer.self_attn.o_proj.fastlora_hidden_state_norm.weight', 'base_model.model.model.layers.15.base_layer.self_attn.o_proj.fastlora_A1.weight', 'base_model.model.model.layers.15.base_layer.self_attn.o_proj.fastlora_A2.weight', 'base_model.model.model.layers.15.base_layer.self_attn.o_proj.fastlora_A3.weight', 'base_model.model.model.layers.15.base_layer.self_attn.o_proj.fastlora_B.weight', 'base_model.model.model.layers.15.base_layer.self_attn.o_proj.fastlora_hidden_state_norm.weight', 'base_model.model.model.layers.16.base_layer.self_attn.o_proj.fastlora_A1.weight', 'base_model.model.model.layers.16.base_layer.self_attn.o_proj.fastlora_A2.weight', 'base_model.model.model.layers.16.base_layer.self_attn.o_proj.fastlora_A3.weight', 'base_model.model.model.layers.16.base_layer.self_attn.o_proj.fastlora_B.weight', 'base_model.model.model.layers.16.base_layer.self_attn.o_proj.fastlora_hidden_state_norm.weight', 'base_model.model.model.layers.17.base_layer.self_attn.o_proj.fastlora_A1.weight', 'base_model.model.model.layers.17.base_layer.self_attn.o_proj.fastlora_A2.weight', 'base_model.model.model.layers.17.base_layer.self_attn.o_proj.fastlora_A3.weight', 'base_model.model.model.layers.17.base_layer.self_attn.o_proj.fastlora_B.weight', 'base_model.model.model.layers.17.base_layer.self_attn.o_proj.fastlora_hidden_state_norm.weight', 'base_model.model.model.layers.18.base_layer.self_attn.o_proj.fastlora_A1.weight', 'base_model.model.model.layers.18.base_layer.self_attn.o_proj.fastlora_A2.weight', 'base_model.model.model.layers.18.base_layer.self_attn.o_proj.fastlora_A3.weight', 'base_model.model.model.layers.18.base_layer.self_attn.o_proj.fastlora_B.weight', 'base_model.model.model.layers.18.base_layer.self_attn.o_proj.fastlora_hidden_state_norm.weight', 'base_model.model.model.layers.19.base_layer.self_attn.o_proj.fastlora_A1.weight', 'base_model.model.model.layers.19.base_layer.self_attn.o_proj.fastlora_A2.weight', 'base_model.model.model.layers.19.base_layer.self_attn.o_proj.fastlora_A3.weight', 'base_model.model.model.layers.19.base_layer.self_attn.o_proj.fastlora_B.weight', 'base_model.model.model.layers.19.base_layer.self_attn.o_proj.fastlora_hidden_state_norm.weight', 'base_model.model.model.layers.2.base_layer.self_attn.o_proj.fastlora_A1.weight', 'base_model.model.model.layers.2.base_layer.self_attn.o_proj.fastlora_A2.weight', 'base_model.model.model.layers.2.base_layer.self_attn.o_proj.fastlora_A3.weight', 'base_model.model.model.layers.2.base_layer.self_attn.o_proj.fastlora_B.weight', 'base_model.model.model.layers.2.base_layer.self_attn.o_proj.fastlora_hidden_state_norm.weight', 'base_model.model.model.layers.20.base_layer.self_attn.o_proj.fastlora_A1.weight', 'base_model.model.model.layers.20.base_layer.self_attn.o_proj.fastlora_A2.weight', 'base_model.model.model.layers.20.base_layer.self_attn.o_proj.fastlora_A3.weight', 'base_model.model.model.layers.20.base_layer.self_attn.o_proj.fastlora_B.weight', 'base_model.model.model.layers.20.base_layer.self_attn.o_proj.fastlora_hidden_state_norm.weight', 'base_model.model.model.layers.21.base_layer.self_attn.o_proj.fastlora_A1.weight', 'base_model.model.model.layers.21.base_layer.self_attn.o_proj.fastlora_A2.weight', 'base_model.model.model.layers.21.base_layer.self_attn.o_proj.fastlora_A3.weight', 'base_model.model.model.layers.21.base_layer.self_attn.o_proj.fastlora_B.weight', 'base_model.model.model.layers.21.base_layer.self_attn.o_proj.fastlora_hidden_state_norm.weight', 'base_model.model.model.layers.22.base_layer.self_attn.o_proj.fastlora_A1.weight', 'base_model.model.model.layers.22.base_layer.self_attn.o_proj.fastlora_A2.weight', 'base_model.model.model.layers.22.base_layer.self_attn.o_proj.fastlora_A3.weight', 'base_model.model.model.layers.22.base_layer.self_attn.o_proj.fastlora_B.weight', 'base_model.model.model.layers.22.base_layer.self_attn.o_proj.fastlora_hidden_state_norm.weight', 'base_model.model.model.layers.23.base_layer.self_attn.o_proj.fastlora_A1.weight', 'base_model.model.model.layers.23.base_layer.self_attn.o_proj.fastlora_A2.weight', 'base_model.model.model.layers.23.base_layer.self_attn.o_proj.fastlora_A3.weight', 'base_model.model.model.layers.23.base_layer.self_attn.o_proj.fastlora_B.weight', 'base_model.model.model.layers.23.base_layer.self_attn.o_proj.fastlora_hidden_state_norm.weight', 'base_model.model.model.layers.24.base_layer.self_attn.o_proj.fastlora_A1.weight', 'base_model.model.model.layers.24.base_layer.self_attn.o_proj.fastlora_A2.weight', 'base_model.model.model.layers.24.base_layer.self_attn.o_proj.fastlora_A3.weight', 'base_model.model.model.layers.24.base_layer.self_attn.o_proj.fastlora_B.weight', 'base_model.model.model.layers.24.base_layer.self_attn.o_proj.fastlora_hidden_state_norm.weight', 'base_model.model.model.layers.25.base_layer.self_attn.o_proj.fastlora_A1.weight', 'base_model.model.model.layers.25.base_layer.self_attn.o_proj.fastlora_A2.weight', 'base_model.model.model.layers.25.base_layer.self_attn.o_proj.fastlora_A3.weight', 'base_model.model.model.layers.25.base_layer.self_attn.o_proj.fastlora_B.weight', 'base_model.model.model.layers.25.base_layer.self_attn.o_proj.fastlora_hidden_state_norm.weight', 'base_model.model.model.layers.26.base_layer.self_attn.o_proj.fastlora_A1.weight', 'base_model.model.model.layers.26.base_layer.self_attn.o_proj.fastlora_A2.weight', 'base_model.model.model.layers.26.base_layer.self_attn.o_proj.fastlora_A3.weight', 'base_model.model.model.layers.26.base_layer.self_attn.o_proj.fastlora_B.weight', 'base_model.model.model.layers.26.base_layer.self_attn.o_proj.fastlora_hidden_state_norm.weight', 'base_model.model.model.layers.27.base_layer.self_attn.o_proj.fastlora_A1.weight', 'base_model.model.model.layers.27.base_layer.self_attn.o_proj.fastlora_A2.weight', 'base_model.model.model.layers.27.base_layer.self_attn.o_proj.fastlora_A3.weight', 'base_model.model.model.layers.27.base_layer.self_attn.o_proj.fastlora_B.weight', 'base_model.model.model.layers.27.base_layer.self_attn.o_proj.fastlora_hidden_state_norm.weight', 'base_model.model.model.layers.28.base_layer.self_attn.o_proj.fastlora_A1.weight', 'base_model.model.model.layers.28.base_layer.self_attn.o_proj.fastlora_A2.weight', 'base_model.model.model.layers.28.base_layer.self_attn.o_proj.fastlora_A3.weight', 'base_model.model.model.layers.28.base_layer.self_attn.o_proj.fastlora_B.weight', 'base_model.model.model.layers.28.base_layer.self_attn.o_proj.fastlora_hidden_state_norm.weight', 'base_model.model.model.layers.29.base_layer.self_attn.o_proj.fastlora_A1.weight', 'base_model.model.model.layers.29.base_layer.self_attn.o_proj.fastlora_A2.weight', 'base_model.model.model.layers.29.base_layer.self_attn.o_proj.fastlora_A3.weight', 'base_model.model.model.layers.29.base_layer.self_attn.o_proj.fastlora_B.weight', 'base_model.model.model.layers.29.base_layer.self_attn.o_proj.fastlora_hidden_state_norm.weight', 'base_model.model.model.layers.3.base_layer.self_attn.o_proj.fastlora_A1.weight', 'base_model.model.model.layers.3.base_layer.self_attn.o_proj.fastlora_A2.weight', 'base_model.model.model.layers.3.base_layer.self_attn.o_proj.fastlora_A3.weight', 'base_model.model.model.layers.3.base_layer.self_attn.o_proj.fastlora_B.weight', 'base_model.model.model.layers.3.base_layer.self_attn.o_proj.fastlora_hidden_state_norm.weight', 'base_model.model.model.layers.30.base_layer.self_attn.o_proj.fastlora_A1.weight', 'base_model.model.model.layers.30.base_layer.self_attn.o_proj.fastlora_A2.weight', 'base_model.model.model.layers.30.base_layer.self_attn.o_proj.fastlora_A3.weight', 'base_model.model.model.layers.30.base_layer.self_attn.o_proj.fastlora_B.weight', 'base_model.model.model.layers.30.base_layer.self_attn.o_proj.fastlora_hidden_state_norm.weight', 'base_model.model.model.layers.31.base_layer.self_attn.o_proj.fastlora_A1.weight', 'base_model.model.model.layers.31.base_layer.self_attn.o_proj.fastlora_A2.weight', 'base_model.model.model.layers.31.base_layer.self_attn.o_proj.fastlora_A3.weight', 'base_model.model.model.layers.31.base_layer.self_attn.o_proj.fastlora_B.weight', 'base_model.model.model.layers.31.base_layer.self_attn.o_proj.fastlora_hidden_state_norm.weight', 'base_model.model.model.layers.4.base_layer.self_attn.o_proj.fastlora_A1.weight', 'base_model.model.model.layers.4.base_layer.self_attn.o_proj.fastlora_A2.weight', 'base_model.model.model.layers.4.base_layer.self_attn.o_proj.fastlora_A3.weight', 'base_model.model.model.layers.4.base_layer.self_attn.o_proj.fastlora_B.weight', 'base_model.model.model.layers.4.base_layer.self_attn.o_proj.fastlora_hidden_state_norm.weight', 'base_model.model.model.layers.5.base_layer.self_attn.o_proj.fastlora_A1.weight', 'base_model.model.model.layers.5.base_layer.self_attn.o_proj.fastlora_A2.weight', 'base_model.model.model.layers.5.base_layer.self_attn.o_proj.fastlora_A3.weight', 'base_model.model.model.layers.5.base_layer.self_attn.o_proj.fastlora_B.weight', 'base_model.model.model.layers.5.base_layer.self_attn.o_proj.fastlora_hidden_state_norm.weight', 'base_model.model.model.layers.6.base_layer.self_attn.o_proj.fastlora_A1.weight', 'base_model.model.model.layers.6.base_layer.self_attn.o_proj.fastlora_A2.weight', 'base_model.model.model.layers.6.base_layer.self_attn.o_proj.fastlora_A3.weight', 'base_model.model.model.layers.6.base_layer.self_attn.o_proj.fastlora_B.weight', 'base_model.model.model.layers.6.base_layer.self_attn.o_proj.fastlora_hidden_state_norm.weight', 'base_model.model.model.layers.7.base_layer.self_attn.o_proj.fastlora_A1.weight', 'base_model.model.model.layers.7.base_layer.self_attn.o_proj.fastlora_A2.weight', 'base_model.model.model.layers.7.base_layer.self_attn.o_proj.fastlora_A3.weight', 'base_model.model.model.layers.7.base_layer.self_attn.o_proj.fastlora_B.weight', 'base_model.model.model.layers.7.base_layer.self_attn.o_proj.fastlora_hidden_state_norm.weight', 'base_model.model.model.layers.8.base_layer.self_attn.o_proj.fastlora_A1.weight', 'base_model.model.model.layers.8.base_layer.self_attn.o_proj.fastlora_A2.weight', 'base_model.model.model.layers.8.base_layer.self_attn.o_proj.fastlora_A3.weight', 'base_model.model.model.layers.8.base_layer.self_attn.o_proj.fastlora_B.weight', 'base_model.model.model.layers.8.base_layer.self_attn.o_proj.fastlora_hidden_state_norm.weight', 'base_model.model.model.layers.9.base_layer.self_attn.o_proj.fastlora_A1.weight', 'base_model.model.model.layers.9.base_layer.self_attn.o_proj.fastlora_A2.weight', 'base_model.model.model.layers.9.base_layer.self_attn.o_proj.fastlora_A3.weight', 'base_model.model.model.layers.9.base_layer.self_attn.o_proj.fastlora_B.weight', 'base_model.model.model.layers.9.base_layer.self_attn.o_proj.fastlora_hidden_state_norm.weight'])\n"
     ]
    }
   ],
   "source": [
    "# Load the PEFT configuration from the given pretrained model directory.\n",
    "peft_config = PeftConfig.from_pretrained(model_name_or_path)\n",
    "\n",
    "# Get the base model path from the configuration.\n",
    "base_model_path = peft_config.base_model_name_or_path\n",
    "\n",
    "# Ensure that the base model path is available.\n",
    "assert base_model_path is not None, \"base_model_name_or_path should not be None\"\n",
    "\n",
    "# Load the base causal language model from the retrieved base model path.\n",
    "# The model is loaded with a specific data type and attention implementation.\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_path,\n",
    "    torch_dtype=torch_dtype,\n",
    "    attn_implementation=attn_implementation,\n",
    ")\n",
    "\n",
    "# Load the FastLora model for causal language modeling.\n",
    "# This model is built on top of the base model, uses the adapter settings from the PEFT config,\n",
    "# is not set for training, and is moved to the GPU.\n",
    "model = FastLoraModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    model_name_or_path,\n",
    "    adapter_name='default',\n",
    "    is_trainable=False,\n",
    "    config=peft_config,\n",
    ").cuda()\n",
    "\n",
    "# Load the tokenizer from the pretrained model directory.\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a prompt prefix that supplies context about a speaker's background.\n",
    "# This information may influence how the model generates the response.\n",
    "prompt_prefix = (\n",
    "    \"I volunteer in my spare time. I have been volunteering for 7 years. I volunteer in a homeless shelter in my town. \"\n",
    "    \"I'm not into cars. I wrestle for my day job. I like wrestling. I am not super into wrestling. I like crowds and meeting people. \"\n",
    "    \"I work out a few times each week when I need to be alone. I like country music a little bit. I like Taylor Swift. \"\n",
    "    \"I've lost fights recently. I work out a few times a week. I do not like working on cars. I am not patient. \"\n",
    "    \"I have two dogs: Baron Zemo and Spike. I have two older mustangs. I like vintage cars. I'm working on two Mustangs: a 68 and a 66 Hertz clone. \"\n",
    "    \"I've been working on cars since 1989. I have a Mustang convertible. I work on my car after work. I get frustrated working on my car sometimes. \"\n",
    "    \"I don't like crowds. I like working out. I like classic country. I am a dog trainer. My work keeps me busy.\"\n",
    ")\n",
    "\n",
    "# Define the input prompt that asks a question related to music.\n",
    "prompt_input = \"Hey, remember that time we talked about music? What was the artist you mentioned you could get into?\"\n",
    "\n",
    "# Set parameters for generating the LoRA weights and the text output.\n",
    "merge_strategy = 'concat'\n",
    "window_size = 1024\n",
    "max_new_tokens = 100\n",
    "stop = [\"\\n\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of context_input_ids: torch.Size([1, 1, 237])\n",
      "shape of context_attention_mask: torch.Size([1, 1, 237])\n",
      "Number of LoRA weights generated: 32\n"
     ]
    }
   ],
   "source": [
    "# Generate LoRA weights using the model, tokenizer, and prompt prefix.\n",
    "# This function adapts the model weights based on the given prompt context.\n",
    "lora_weights = fastlora_generate_adaptor(\n",
    "    model, tokenizer, \n",
    "    prompt_prefix, \n",
    "    merge_strategy=merge_strategy, \n",
    "    max_window_size=window_size,\n",
    ")\n",
    "\n",
    "# Output the number of LoRA weights generated.\n",
    "print(\"Number of LoRA weights generated:\", len(lora_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like Taylor Swift.\n"
     ]
    }
   ],
   "source": [
    "# Generate text using the model with the generated LoRA weights.\n",
    "# The function takes the input prompt and uses chat-style generation.\n",
    "output_text = fastlora_conditional_generate(\n",
    "    model, tokenizer, \n",
    "    input_text=prompt_input, \n",
    "    use_chat=True,\n",
    "    mode=\"weights\", \n",
    "    lora_weights=lora_weights, \n",
    "    max_new_tokens=max_new_tokens,\n",
    "    stop=stop,\n",
    ")\n",
    "\n",
    "# Print the generated text.\n",
    "print(output_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen-adp-a40",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
